{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script is designed to implement a product reccomendation system for e-commerce users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# User based collaborative filtering\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Content based filtering\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load from .env file\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "\n",
    "load_dotenv(f'{parent_dir}/.env')\n",
    "\n",
    "postgres_password = os.getenv('POSTGRES_PASSWORD')\n",
    "postgres_port_no = os.getenv('POSTGRES_PORT_NO')\n",
    "host = os.getenv('POSTGRES_HOST')\n",
    "database = os.getenv('POSTGRES_DB')\n",
    "user = os.getenv('POSTGRES_USER')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "online_sales = pd.read_csv('../data/online_sales_edited.csv')\n",
    "products = pd.read_csv('../data/products.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 53701 entries, 0 to 53700\n",
      "Data columns (total 9 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   user_id           53701 non-null  int64  \n",
      " 1   transaction_id    53701 non-null  int64  \n",
      " 2   date              53701 non-null  object \n",
      " 3   product_id        53701 non-null  object \n",
      " 4   Quantity          53701 non-null  int64  \n",
      " 5   Delivery_Charges  53701 non-null  float64\n",
      " 6   Coupon_Status     53701 non-null  object \n",
      " 7   Coupon_Code       53701 non-null  object \n",
      " 8   Discount_pct      53701 non-null  float64\n",
      "dtypes: float64(2), int64(3), object(4)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "source": [
    "online_sales.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1351 entries, 0 to 1350\n",
      "Data columns (total 7 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   product_id           1351 non-null   object \n",
      " 1   product_name         1351 non-null   object \n",
      " 2   about_product        1351 non-null   object \n",
      " 3   category             1351 non-null   object \n",
      " 4   actual_price         1351 non-null   float64\n",
      " 5   discounted_price     1351 non-null   float64\n",
      " 6   discount_percentage  1351 non-null   float64\n",
      "dtypes: float64(3), object(4)\n",
      "memory usage: 74.0+ KB\n"
     ]
    }
   ],
   "source": [
    "products.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# left join online_sales and products\n",
    "\n",
    "df = pd.merge(online_sales, products, on='product_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 53701 entries, 0 to 53700\n",
      "Data columns (total 15 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   user_id              53701 non-null  int64  \n",
      " 1   transaction_id       53701 non-null  int64  \n",
      " 2   date                 53701 non-null  object \n",
      " 3   product_id           53701 non-null  object \n",
      " 4   Quantity             53701 non-null  int64  \n",
      " 5   Delivery_Charges     53701 non-null  float64\n",
      " 6   Coupon_Status        53701 non-null  object \n",
      " 7   Coupon_Code          53701 non-null  object \n",
      " 8   Discount_pct         53701 non-null  float64\n",
      " 9   product_name         53701 non-null  object \n",
      " 10  about_product        53701 non-null  object \n",
      " 11  category             53701 non-null  object \n",
      " 12  actual_price         53701 non-null  float64\n",
      " 13  discounted_price     53701 non-null  float64\n",
      " 14  discount_percentage  53701 non-null  float64\n",
      "dtypes: float64(5), int64(3), object(7)\n",
      "memory usage: 6.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>transaction_id</th>\n",
       "      <th>date</th>\n",
       "      <th>product_id</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Delivery_Charges</th>\n",
       "      <th>Coupon_Status</th>\n",
       "      <th>Coupon_Code</th>\n",
       "      <th>Discount_pct</th>\n",
       "      <th>product_name</th>\n",
       "      <th>about_product</th>\n",
       "      <th>category</th>\n",
       "      <th>actual_price</th>\n",
       "      <th>discounted_price</th>\n",
       "      <th>discount_percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17850</td>\n",
       "      <td>16679</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>B09DL9978Y</td>\n",
       "      <td>1</td>\n",
       "      <td>6.5</td>\n",
       "      <td>Used</td>\n",
       "      <td>ELEC10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Hindware Atlantic Compacto 3 Litre Instant wat...</td>\n",
       "      <td>Stainless Steel Tank|Copper Heating element|IS...</td>\n",
       "      <td>Home&amp;Kitchen|Heating,Cooling&amp;AirQuality|WaterH...</td>\n",
       "      <td>55.08</td>\n",
       "      <td>28.79</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17850</td>\n",
       "      <td>16680</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>B09DL9978Y</td>\n",
       "      <td>1</td>\n",
       "      <td>6.5</td>\n",
       "      <td>Used</td>\n",
       "      <td>ELEC10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Hindware Atlantic Compacto 3 Litre Instant wat...</td>\n",
       "      <td>Stainless Steel Tank|Copper Heating element|IS...</td>\n",
       "      <td>Home&amp;Kitchen|Heating,Cooling&amp;AirQuality|WaterH...</td>\n",
       "      <td>55.08</td>\n",
       "      <td>28.79</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17850</td>\n",
       "      <td>16681</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>B07GXHC691</td>\n",
       "      <td>1</td>\n",
       "      <td>6.5</td>\n",
       "      <td>Used</td>\n",
       "      <td>OFF10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>STRIFF PS2_01 Multi Angle Mobile/Tablet Tablet...</td>\n",
       "      <td>[PORTABLE SIZE]- 98mm*96mm*19mm, STRIFF desk p...</td>\n",
       "      <td>Electronics|Mobiles&amp;Accessories|MobileAccessor...</td>\n",
       "      <td>5.99</td>\n",
       "      <td>1.19</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17850</td>\n",
       "      <td>16682</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>B08NCKT9FG</td>\n",
       "      <td>5</td>\n",
       "      <td>6.5</td>\n",
       "      <td>Not Used</td>\n",
       "      <td>SALE10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Boat A 350 Type C Cable 1.5m(Jet Black)</td>\n",
       "      <td>2 years warranty from the date of purchase, yo...</td>\n",
       "      <td>Computers&amp;Accessories|Accessories&amp;Peripherals|...</td>\n",
       "      <td>9.58</td>\n",
       "      <td>3.59</td>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17850</td>\n",
       "      <td>16682</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>B08H21B6V7</td>\n",
       "      <td>1</td>\n",
       "      <td>6.5</td>\n",
       "      <td>Used</td>\n",
       "      <td>AIO10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Nokia 150 (2020) (Cyan)</td>\n",
       "      <td>MicroSD card slot expandable up to 32. Network...</td>\n",
       "      <td>Electronics|Mobiles&amp;Accessories|Smartphones&amp;Ba...</td>\n",
       "      <td>35.99</td>\n",
       "      <td>31.19</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  transaction_id        date  product_id  Quantity  \\\n",
       "0    17850           16679  2019-01-01  B09DL9978Y         1   \n",
       "1    17850           16680  2019-01-01  B09DL9978Y         1   \n",
       "2    17850           16681  2019-01-01  B07GXHC691         1   \n",
       "3    17850           16682  2019-01-01  B08NCKT9FG         5   \n",
       "4    17850           16682  2019-01-01  B08H21B6V7         1   \n",
       "\n",
       "   Delivery_Charges Coupon_Status Coupon_Code  Discount_pct  \\\n",
       "0               6.5          Used      ELEC10           0.1   \n",
       "1               6.5          Used      ELEC10           0.1   \n",
       "2               6.5          Used       OFF10           0.1   \n",
       "3               6.5      Not Used      SALE10           0.1   \n",
       "4               6.5          Used       AIO10           0.1   \n",
       "\n",
       "                                        product_name  \\\n",
       "0  Hindware Atlantic Compacto 3 Litre Instant wat...   \n",
       "1  Hindware Atlantic Compacto 3 Litre Instant wat...   \n",
       "2  STRIFF PS2_01 Multi Angle Mobile/Tablet Tablet...   \n",
       "3            Boat A 350 Type C Cable 1.5m(Jet Black)   \n",
       "4                            Nokia 150 (2020) (Cyan)   \n",
       "\n",
       "                                       about_product  \\\n",
       "0  Stainless Steel Tank|Copper Heating element|IS...   \n",
       "1  Stainless Steel Tank|Copper Heating element|IS...   \n",
       "2  [PORTABLE SIZE]- 98mm*96mm*19mm, STRIFF desk p...   \n",
       "3  2 years warranty from the date of purchase, yo...   \n",
       "4  MicroSD card slot expandable up to 32. Network...   \n",
       "\n",
       "                                            category  actual_price  \\\n",
       "0  Home&Kitchen|Heating,Cooling&AirQuality|WaterH...         55.08   \n",
       "1  Home&Kitchen|Heating,Cooling&AirQuality|WaterH...         55.08   \n",
       "2  Electronics|Mobiles&Accessories|MobileAccessor...          5.99   \n",
       "3  Computers&Accessories|Accessories&Peripherals|...          9.58   \n",
       "4  Electronics|Mobiles&Accessories|Smartphones&Ba...         35.99   \n",
       "\n",
       "   discounted_price  discount_percentage  \n",
       "0             28.79                 0.48  \n",
       "1             28.79                 0.48  \n",
       "2              1.19                 0.80  \n",
       "3              3.59                 0.63  \n",
       "4             31.19                 0.13  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure 'Quantity' is non-negative\n",
    "df = df[df['Quantity'] > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User-based collaborative filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User-Based Collaborative Filtering provides personalized recommendations by leveraging similarities between users' purchasing behaviors computed based on cosine similarity between users, making it intuitive and easy to implement without relying on product metadata. This approach fosters tailored user experiences and can uncover serendipitous product discoveries. However, UBCF faces challenges such as scalability issues with large user bases, data sparsity that can limit the effectiveness of similarity measures, and the cold start problem where new users or products lack sufficient interaction data. Additionally, it may suffer from popularity bias, leading to less diverse recommendations. Balancing these strengths and limitations is key to optimizing UBCF for an effective e-commerce recommendation system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_based_recommendation(user_id, df, top_n=5):\n",
    "    \"\"\"\n",
    "    Recommend top N products for a given user based on user similarity.\n",
    "\n",
    "    Parameters:\n",
    "    - user_id (int): The ID of the user for whom to generate recommendations.\n",
    "    - df (DataFrame): The preprocessed DataFrame containing user transactions.\n",
    "    - top_n (int): Number of top recommendations to return.\n",
    "\n",
    "    Returns:\n",
    "    - recommendations (list): List of recommended product IDs.\n",
    "    \"\"\"\n",
    "\n",
    "    # Check if the user_id exists in the DataFrame\n",
    "    if user_id not in df['user_id'].unique():\n",
    "        print(f\"User ID {user_id} not found in the dataset.\")\n",
    "        return []\n",
    "\n",
    "    # 1. Create the User-Item Matrix\n",
    "    user_item_matrix = df.pivot_table(index='user_id',\n",
    "                                      columns='product_id',\n",
    "                                      values='Quantity',\n",
    "                                      aggfunc='sum',\n",
    "                                      fill_value=0)\n",
    "\n",
    "    # 2. Compute User Similarity Matrix using Cosine Similarity\n",
    "    # Cosine similarity returns values between 0 and 1\n",
    "    similarity_matrix = cosine_similarity(user_item_matrix)\n",
    "    \n",
    "    # Convert the similarity matrix to a DataFrame for easier handling\n",
    "    similarity_df = pd.DataFrame(similarity_matrix, \n",
    "                                 index=user_item_matrix.index, \n",
    "                                 columns=user_item_matrix.index)\n",
    "\n",
    "    # 3. Find Similar Users\n",
    "    # Get similarity scores for the target user\n",
    "    user_similarities = similarity_df[user_id].sort_values(ascending=False)\n",
    "    \n",
    "    # Exclude the target user from the similarity scores\n",
    "    user_similarities = user_similarities.drop(labels=[user_id])\n",
    "\n",
    "    # Select top similar users (you can adjust the number, e.g., top 10)\n",
    "    top_similar_users = user_similarities.head(10).index.tolist()\n",
    "\n",
    "    if not top_similar_users:\n",
    "        print(f\"No similar users found for User ID {user_id}.\")\n",
    "        return []\n",
    "\n",
    "    # 4. Aggregate Products from Similar Users\n",
    "    # Select the purchase data of similar users\n",
    "    similar_users_data = df[df['user_id'].isin(top_similar_users)]\n",
    "\n",
    "    # Aggregate the quantities for each product from similar users\n",
    "    product_scores = similar_users_data.groupby('product_id')['Quantity'].sum()\n",
    "\n",
    "    # 5. Exclude Products Already Purchased by the Target User\n",
    "    # Get the list of products already purchased by the target user\n",
    "    user_purchased_products = df[df['user_id'] == user_id]['product_id'].unique()\n",
    "\n",
    "    # Remove these products from the recommendation candidates\n",
    "    product_scores = product_scores.drop(labels=user_purchased_products, errors='ignore')\n",
    "\n",
    "    if product_scores.empty:\n",
    "        print(f\"No new products to recommend for User ID {user_id}.\")\n",
    "        return []\n",
    "\n",
    "    # 6. Sort the products based on the aggregated scores in descending order\n",
    "    sorted_products = product_scores.sort_values(ascending=False)\n",
    "\n",
    "    # 7. Select the Top N Products\n",
    "    recommended_products = sorted_products.head(top_n).index.tolist()\n",
    "\n",
    "    # Print the recommended products with their names\n",
    "    recommended_product_names = products[products['product_id'].isin(recommended_products)]['product_name'].tolist()\n",
    "\n",
    "    return recommended_products, recommended_product_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['B078KRFWQB', 'B07LFWP97N', 'B07VX71FZP', 'B078W65FJ7', 'B0B61HYR92'],\n",
       " ['Lapster usb 2.0 mantra cable, mantra mfs 100 data cable (black)',\n",
       "  'Gizga Essentials Laptop Bag Sleeve Case Cover Pouch with Handle for 14.1 Inch Laptop for Men & Women, Padded Laptop Compartment, Premium Zipper Closure, Water Repellent Nylon Fabric, Grey',\n",
       "  'boAt BassHeads 900 On-Ear Wired Headphones with Mic (White)',\n",
       "  'Amazon Brand - Solimo 2000/1000 Watts Room Heater with Adjustable Thermostat (ISI certified, White colour, Ideal for small to medium room/area)',\n",
       "  'Havells Cista Room Heater, White, 2000 Watts'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_based_recommendation(12583, df, top_n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content based reccomendation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function aims to generate personalized product recommendations for a user by analyzing the content (attributes) of products they have previously purchased. It uses a content-based filtering approach, which relies on the similarity between product attributes to suggest new products that are similar to those the user has already bought.\n",
    "\n",
    "To encourage upselling, higher prices item are reccomended back to the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to preprocess text\n",
    "def preprocess_text(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    stemmer = PorterStemmer()\n",
    "    \n",
    "    # Tokenize, remove stop words, and apply stemming\n",
    "    tokens = text.split()\n",
    "    tokens = [stemmer.stem(word) for word in tokens if word.lower() not in stop_words]\n",
    "    \n",
    "    return ' '.join(tokens)\n",
    "\n",
    "def content_based_recommendation(user_id, transactions_df, products_df, top_n=5):\n",
    "    \"\"\"\n",
    "    Recommend top N products for a given user based on content similarity.\n",
    "    \n",
    "    Parameters:\n",
    "    - user_id (int): The ID of the user for whom to generate recommendations.\n",
    "    - transactions_df (DataFrame): The DataFrame containing user transactions.\n",
    "    - products_df (DataFrame): The DataFrame containing product details.\n",
    "    - top_n (int): Number of top recommendations to return.\n",
    "    \n",
    "    Returns:\n",
    "    - recommendations (list): List of recommended product IDs.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Check if the user_id exists in the transactions DataFrame\n",
    "    if user_id not in transactions_df['user_id'].unique():\n",
    "        print(f\"User ID {user_id} not found in the dataset.\")\n",
    "        return []\n",
    "\n",
    "    # 1. Create a new feature by combining relevant product attributes in the products DataFrame\n",
    "    products_df['combined_features'] = products_df['product_name'] + ' ' + products_df['about_product'] + ' ' + products_df['category']\n",
    "    \n",
    "    # 2. Apply text preprocessing to the combined features\n",
    "    products_df['combined_features'] = products_df['combined_features'].apply(preprocess_text)\n",
    "    \n",
    "    # 3. Remove duplicate products to ensure each product is unique\n",
    "    products_df = products_df[['product_id', 'combined_features','actual_price']].drop_duplicates().reset_index(drop=True)\n",
    "    \n",
    "    # 4. Initialize the TF-IDF Vectorizer\n",
    "    tfidf = TfidfVectorizer(stop_words='english')\n",
    "    \n",
    "    # 5. Fit and transform the combined features\n",
    "    tfidf_matrix = tfidf.fit_transform(products_df['combined_features'])\n",
    "    \n",
    "    # 6. Compute the cosine similarity matrix\n",
    "    cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
    "    \n",
    "    # 7. Create a reverse mapping of product indices and IDs\n",
    "    indices = pd.Series(products_df.index, index=products_df['product_id']).drop_duplicates()\n",
    "    \n",
    "    # 8. Get the list of products purchased by the user from the transactions DataFrame\n",
    "    user_purchases = transactions_df[transactions_df['user_id'] == user_id]['product_id'].unique()\n",
    "    \n",
    "    # 9. Initialize a series to hold similarity scores\n",
    "    similarity_scores = pd.Series(dtype=float)\n",
    "    \n",
    "    # 10. Iterate over each purchased product and accumulate similarity scores\n",
    "    for product_id in user_purchases:\n",
    "        if product_id not in indices:\n",
    "            continue  # Skip if the product_id is not in the dataset\n",
    "        idx = indices[product_id]\n",
    "        sim_scores = pd.Series(cosine_sim[idx]).sort_values(ascending=False)\n",
    "        sim_scores = sim_scores.iloc[1:]  # Exclude the product itself\n",
    "        similarity_scores = similarity_scores.add(sim_scores, fill_value=0)\n",
    "    \n",
    "    if similarity_scores.empty:\n",
    "        print(f\"No similar products found for User ID {user_id}.\")\n",
    "        return []\n",
    "    \n",
    "    # 11. Remove products already purchased by the user\n",
    "    similarity_scores = similarity_scores.drop(labels=[indices[pid] for pid in user_purchases if pid in indices], errors='ignore')\n",
    "    \n",
    "    if similarity_scores.empty:\n",
    "        print(f\"No new products to recommend for User ID {user_id}.\")\n",
    "        return []\n",
    "    \n",
    "    # 12. Sort the products based on similarity scores and price (for upselling)\n",
    "    similarity_scores = similarity_scores.sort_values(ascending=False)\n",
    "    top_indices = similarity_scores.head(top_n * 2).index.tolist()  # Get more candidates\n",
    "    \n",
    "    # 13. Map indices back to product IDs and filter by price\n",
    "    recommended_products = products_df.iloc[top_indices]\n",
    "    recommended_products = recommended_products.sort_values(by='actual_price', ascending=False)  # Prioritize higher-priced items\n",
    "    recommended_product_ids = recommended_products.head(top_n)['product_id'].tolist()\n",
    "    \n",
    "    return recommended_product_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B0BC8BQ432', 'B095JQVC7N', 'B0B997FBZT', 'B0B1YZ9CB8', 'B0B1YZX72F']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_based_recommendation(12583, df, products, top_n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coldstart Reccomendation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cold_start_recommendation function provides a practical solution for recommending products to new users by leveraging the popularity of products. This approach ensures that new users receive relevant and popular product recommendations, even without prior interaction data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def popularity_based_recommendation(transactions_df, products_df, top_n=5, category=None):\n",
    "    \"\"\"\n",
    "    Recommend top N popular products based on overall sales or within a specific category.\n",
    "    \n",
    "    Parameters:\n",
    "    - transactions_df (DataFrame): DataFrame containing user transactions with columns ['user_id', 'product_id', 'Quantity', ...].\n",
    "    - products_df (DataFrame): DataFrame containing product details with columns ['product_id', 'product_name', 'about_product', 'category', ...].\n",
    "    - top_n (int): Number of top recommendations to return.\n",
    "    - category (str, optional): If specified, recommend popular products within this category.\n",
    "    \n",
    "    Returns:\n",
    "    - recommended_product_ids (list): List of recommended product IDs.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Merge transactions with products to get category information\n",
    "    merged_df = transactions_df.merge(products_df, on='product_id', how='left')\n",
    "    \n",
    "    # If category is specified, filter by category\n",
    "    if category:\n",
    "        merged_df = merged_df[merged_df['category'] == category]\n",
    "    \n",
    "    # Aggregate the total quantity sold for each product\n",
    "    product_sales = merged_df.groupby('product_id')['Quantity'].sum().sort_values(ascending=False)\n",
    "    \n",
    "    # Get the top N product IDs\n",
    "    recommended_product_ids = product_sales.head(top_n).index.tolist()\n",
    "    \n",
    "    return recommended_product_ids\n",
    "\n",
    "def cold_start_recommendation(user_id, transactions_df, products_df, users_df=None, top_n=5):\n",
    "    \"\"\"\n",
    "    Recommend top N products for a new user using a hybrid approach combining popularity and demographic-based recommendations.\n",
    "    \n",
    "    Parameters:\n",
    "    - user_id (int): The ID of the user for whom to generate recommendations.\n",
    "    - transactions_df (DataFrame): DataFrame containing user transactions with columns ['user_id', 'product_id', 'Quantity', ...].\n",
    "    - products_df (DataFrame): DataFrame containing product details with columns ['product_id', 'product_name', 'about_product', 'category', ...].\n",
    "    - users_df (DataFrame, optional): DataFrame containing user demographic details with columns ['user_id', 'age', 'gender', 'location', ...].\n",
    "    - top_n (int): Number of top recommendations to return.\n",
    "    \n",
    "    Returns:\n",
    "    - recommended_product_ids (list): List of recommended product IDs.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Check if the user exists in the transactions (i.e., is not a new user)\n",
    "    if user_id in transactions_df['user_id'].unique():\n",
    "        print(f\"User ID {user_id} exists in the dataset. Use user-based or content-based recommendations instead.\")\n",
    "        return []\n",
    "    \n",
    "    # Initialize a dictionary to hold recommendation scores\n",
    "    rec_scores = {}\n",
    "    \n",
    "    popular_recs = popularity_based_recommendation(transactions_df, products_df, top_n=top_n*2)\n",
    "    for pid in popular_recs:\n",
    "        rec_scores[pid] = rec_scores.get(pid, 0) + 1  # Weight can be adjusted as needed\n",
    "\n",
    "    # Sort the products based on accumulated scores in descending order\n",
    "    sorted_recs = sorted(rec_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Extract product IDs from the sorted list\n",
    "    recommended_product_ids = [pid for pid, score in sorted_recs]\n",
    "    \n",
    "    # Remove duplicates while preserving order\n",
    "    recommended_product_ids = list(dict.fromkeys(recommended_product_ids))\n",
    "    \n",
    "    # Limit to top_n recommendations\n",
    "    recommended_product_ids = recommended_product_ids[:top_n]\n",
    "    \n",
    "    # If not enough recommendations, fallback to popularity-based\n",
    "    if len(recommended_product_ids) < top_n:\n",
    "        additional_recs = popularity_based_recommendation(transactions_df, products_df, top_n=top_n - len(recommended_product_ids))\n",
    "        # Append additional recommendations, ensuring no duplicates\n",
    "        for pid in additional_recs:\n",
    "            if pid not in recommended_product_ids:\n",
    "                recommended_product_ids.append(pid)\n",
    "            if len(recommended_product_ids) == top_n:\n",
    "                break\n",
    "    \n",
    "    return recommended_product_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overall reccomendation engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this overall reccomendation engine, I have aggregated user based collaborative, content based reccomendation and coldstart reccomendation into a comprehensive system to support each reccomender's pros and cons.I have assigned higher weights to user_based reccomendations (+2) compared to content_based (+1), while ensuring that cold start problem is handled for new users. This reccomendation will be sure to reccomend what people like!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overall_recommendation(user_id, transactions_df, products_df, top_n=5):\n",
    "    \"\"\"\n",
    "    Generate a consolidated list of product recommendations for a user by integrating\n",
    "    User-Based Collaborative Filtering, Content-Based Filtering, and Cold Start strategies.\n",
    "    \n",
    "    Parameters:\n",
    "    - user_id (int): The ID of the user for whom to generate recommendations.\n",
    "    - transactions_df (DataFrame): DataFrame containing user transactions with columns ['user_id', 'product_id', 'Quantity', ...].\n",
    "    - products_df (DataFrame): DataFrame containing product details with columns ['product_id', 'product_name', 'about_product', 'category', ...].\n",
    "    - users_df (DataFrame, optional): DataFrame containing user demographic details with columns ['user_id', 'age', 'gender', 'location', ...].\n",
    "    - top_n (int): Number of top recommendations to return.\n",
    "    \n",
    "    Returns:\n",
    "    - final_recommendations (list): List of recommended product IDs.\n",
    "    - final_recommendation_names (list, optional): List of recommended product names (if available in products_df).\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize a dictionary to hold aggregated recommendation scores\n",
    "    recommendation_scores = {}\n",
    "    \n",
    "    # Check if the user exists in the transactions (i.e., is not a new user)\n",
    "    if user_id in transactions_df['user_id'].unique():\n",
    "        print(f\"Existing User: Generating recommendations using User-Based and Content-Based strategies.\\n\")\n",
    "        \n",
    "        # 1. User-Based Collaborative Filtering Recommendations\n",
    "        print(\"Generating User-Based Collaborative Filtering Recommendations...\")\n",
    "        user_based_recs, user_based_names = user_based_recommendation(user_id, transactions_df, top_n=top_n)\n",
    "        for pid in user_based_recs:\n",
    "            recommendation_scores[pid] = recommendation_scores.get(pid, 0) + 2  # Assign higher weight\n",
    "        \n",
    "        print(\"Generating Content-Based Recommendations...\")\n",
    "        # 2. Content-Based Recommendations\n",
    "        content_based_recs = content_based_recommendation(user_id, transactions_df, products_df, top_n=top_n)\n",
    "        for pid in content_based_recs:\n",
    "            recommendation_scores[pid] = recommendation_scores.get(pid, 0) + 1  # Assign lower weight\n",
    "        \n",
    "    else:\n",
    "        print(f\"New User: Generating recommendations using Cold Start strategy.\")\n",
    "        \n",
    "        # 3. Cold Start Recommendations\n",
    "        cold_start_recs = cold_start_recommendation(user_id, transactions_df, products_df, top_n=top_n)\n",
    "        for pid in cold_start_recs:\n",
    "            recommendation_scores[pid] = recommendation_scores.get(pid, 0) + 1  # Assign weight\n",
    "        \n",
    "    # Convert the recommendation_scores dictionary to a DataFrame for sorting\n",
    "    rec_scores_df = pd.DataFrame(list(recommendation_scores.items()), columns=['product_id', 'score'])\n",
    "    \n",
    "    # Sort the recommendations based on the aggregated scores in descending order\n",
    "    rec_scores_df = rec_scores_df.sort_values(by='score', ascending=False)\n",
    "    \n",
    "    # Extract the top_n product_ids\n",
    "    top_recommendations = rec_scores_df.head(top_n)['product_id'].tolist()\n",
    "    \n",
    "    print(\"Generating Final Recommendations...  Done!\")\n",
    "    # Optionally, retrieve product names for better readability\n",
    "    if 'product_name' in products_df.columns:\n",
    "        # Ensure that all product_ids are present in products_df\n",
    "        valid_pids = [pid for pid in top_recommendations if pid in products_df['product_id'].values]\n",
    "        product_names = products_df.set_index('product_id').loc[valid_pids]['product_name'].tolist()\n",
    "        return top_recommendations, product_names\n",
    "    else:\n",
    "        return top_recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing User: Generating recommendations using User-Based and Content-Based strategies.\n",
      "\n",
      "Generating User-Based Collaborative Filtering Recommendations...\n",
      "Generating Content-Based Recommendations...\n",
      "Generating Final Recommendations...  Done!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['B078KRFWQB', 'B07LFWP97N', 'B07VX71FZP', 'B078W65FJ7', 'B0B61HYR92'],\n",
       " ['Havells Cista Room Heater, White, 2000 Watts',\n",
       "  'Gizga Essentials Laptop Bag Sleeve Case Cover Pouch with Handle for 14.1 Inch Laptop for Men & Women, Padded Laptop Compartment, Premium Zipper Closure, Water Repellent Nylon Fabric, Grey',\n",
       "  'Amazon Brand - Solimo 2000/1000 Watts Room Heater with Adjustable Thermostat (ISI certified, White colour, Ideal for small to medium room/area)',\n",
       "  'boAt BassHeads 900 On-Ear Wired Headphones with Mic (White)',\n",
       "  'Lapster usb 2.0 mantra cable, mantra mfs 100 data cable (black)'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_recommendation(12583, df, products, top_n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation of the reccomendation system will not be included in this project"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
